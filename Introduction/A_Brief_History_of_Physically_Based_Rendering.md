# 基于物理的渲染简史

在20世纪70年代计算机图形学的早期，需要解决的最重要的问题是可见性算法和几何表示等基本问题。当一兆字节的RAM是一种稀有而昂贵的奢侈品，当一台能够进行一百万次浮点操作的计算机花费数十万美元时，计算机图形中可能实现的复杂程度也相应受到限制，任何精确模拟物理进行渲染的尝试都不可行。

随着计算机的能力越来越强大，成本越来越小，因此可以考虑计算要求更高的渲染方法，这反过来又使基于物理的方法变得可行。布林定律巧妙地解释了这一进展："随着技术的进步，渲染时间保持不变。

Jim Blinn 的简单陈述抓住了一个重要的约束：给定一定数量的图像必须渲染（对于研究论文来说，还是对于一部故事片来说，超过十万张），每部图像只需要这么多的处理时间。一个具有一定量的计算可用，并且一个在必须完成渲染之前有一定的时间可用，因此每个图像的最大计算必须受到限制。

Blinn 定律还表明，人们希望渲染的图像与能够渲染的图像之间仍然存在差距：随着计算机速度变快，内容创建者继续使用增强的计算能力，使用更复杂的渲染算法渲染更复杂的场景，而不是呈现与以前相同的场景， 只是更快。渲染继续占用所有可用的计算功能。

## 研究
在20世纪80年代，图形研究人员开始认真考虑基于物理的渲染方法。Whitted的论文（1980年）提出了使用光线跟踪来模拟全局光照效果的想法，为准确模拟场景中光线分布打开了大门。他的方法制作的渲染图像与之前看到的任何图像明显不同，这激起了对这种方法的兴奋。

基于物理的渲染的另一个显著的早期进步是Cook和Torrance的反射模型（1981年，1982年），它引入了微面反射模型到图形。除其他贡献，他们表明，精确建模微面反射，使金属表面准确地呈现;金属没有很好地呈现早期的方法。

不久之后，Goral等人（1984年）将热转印文献与渲染之间连接，展示了如何结合全局漫反射光效果，使用基于物理的光传输近似值。此方法基于有限元方法，场景中的曲面区域相互交换能量。这种方法被称为"辐射"，后称为相关物理单元。Cohen 和Greenberg（1985年）和Nishita 和Nakamae （1985年）的工作之后，又提出了重要的改进.同样，基于物理的方法导致图像具有以前在渲染图像中从未见过的照明效果，这导致许多研究人员在这一领域寻求改进。

虽然辐射方法非常基于物理单位和能量的节约，但随着时间的推移，它显然并没有导致可行的渲染算法：渐近的计算复杂度是难以管理的$O(n^2)$，并且有必要能够沿着阴影边界重新细分几何模型，以取得好的结果;研究者很难为此开发稳健、高效的细分算法，而辐射度在实践中的采用也有限。

在辐射年代，一小群研究人员追求基于物理的渲染方法，这些方法基于光线追踪和蒙特卡罗集成。当时，许多人以怀疑态度看着自己的工作;由于蒙特卡罗集成的差异，图像中令人反感的噪声似乎不可避免，而基于放射性的方法迅速给出了视觉上令人愉悦的结果，至少在相对简单的场景中是这样。

1984年，Cook、Porter和Carpenter引入了分布式光线跟踪，这概括了Whitted的算法，用于计算相机的运动模糊和散焦模糊，光泽表面的模糊反射，以及来自区域光源的照明（Cook等人，1984年），表明光线跟踪能够产生一系列重要的照明效果。

不久之后，Kajiya（1986） 引入了路径追踪;他提出一个严格的渲染问题（光传输积分方程）的公式，并展示了如何应用蒙特卡罗积分来解决它。这项工作需要大量的计算：在 IBM 4341 计算机上渲染两个球体的像素图像，路径跟踪需要 7 小时的计算，首次发布时大约需要 280，000 美元（Farmer 1981）。与冯赫森，卡吉亚还介绍了体积渲染方程的图形（Kajiya和Herzen1984年）;此方程严格描述了参与介质中光的散射。

Cook等人和Kajiya的作品再次导致图像不同于任何以前见过，证明了基于物理的方法的价值。在随后的几年中，Arvo和Kirk（1990年）和Kirk和Arvo（1991年）的论文描述了蒙特卡洛关于逼真的图像合成的重要工作。Shirley的博士论文（1990年）和Shirley等人的后续工作（1996年）是蒙特卡洛工作的重要贡献。Hall的著作《Illumination and Color in Computer Generated Imagery》（1989年）是首批以物理框架呈现渲染的书籍之一，安德鲁·格拉斯纳的《Andrew Glassner’s Principles of Digital Image Synthesis》为该领域奠定了严格的基础（1995年）。Ward 的辐射渲染系统是早期基于物理的开源渲染系统，专注于照明设计（Ward 1994），Slusallek的视觉渲染器旨在弥合基于物理的方法与当时广泛使用的 RenderMan 界面之间的差距，该接口不是基于物理的（Slusallek 1996）。

在Torrance和Cook的工作之后，Cornell大学计算机图形学课程中的许多研究都调查了基于物理的方法。Greenberg等人（1997年）总结了这项工作的动机，他根据对真实物体的物质特性的测量和对人类视觉系统的深入了解，对物理上精确的渲染提出了强有力的论据。

在物理渲染方面，一个关键的一步是 Veach 的工作，在他的论文（Veach 1997）中详细描述了这一点。Veach 为蒙特卡罗渲染提供了先进的关键理论基础，同时开发新的算法，如多重重要性采样、双向路径跟踪和大都会光传输，从而大大提高了其效率。以布林定律为指导，我们认为，这些显著的效率改进对于实际采用这些方法至关重要。

大约在这一天，随着计算机变得越来越快和并行，许多研究人员开始进行实时光线追踪;Wald、Slusallek和Benthin写了一篇有影响力的论文，描述了一种高度优化的光线追踪器，它比之前的光线追踪器效率高得多（Wald等人，2001b）。许多后续论文引入了越来越高效的光线跟踪算法。虽然大部分工作不是基于物理的，但结果导致光线跟踪加速度结构和光线跟踪几何成分的性能取得巨大进展。由于基于物理的渲染通常大量使用光线跟踪，因此此工作又具有与较快的计算机相同的有用效果，因此可以使用物理方法渲染更复杂的场景。

此时，我们将结束对基于物理的渲染研究进展的关键步骤的总结;已经做了很多。本书后续各章的"进一步阅读"部分详细介绍了这一工作。

## 生产
随着20世纪80年代计算机功能的提高，计算机图形可以开始用于动画和电影制作。早期的例子包括Jim Blinn在1981年渲染的《Voyager 2 Flyby of Saturn》和电影《Star Trek II: The Wrath of Khan》（1982年）、《Tron》（1982年）和《The Last Starfighter》（1984年）。

在早期生产使用计算机生成的图像时，基于光栅化的渲染（特别是Reyes算法（Cook等人，1987年））是唯一可行的选择。原因之一是，对于复杂的反射模型或基于物理的光线跟踪可以提供的全局照明效果，没有足够的计算。更重要的是，光栅化具有重要优势，即不需要整个场景表示适合主内存。

当内存不足时，几乎任何有趣的场景都太大，无法放入主内存中。基于光栅化的算法使得渲染场景成为可能，同时在内存中仅具有完整场景表示的一小部分。如果整个场景不能放入主内存，很难实现全局照明效果;多年来，由于计算机系统有限，内容创建者有效地认为几何和纹理的复杂性对于视觉真实感比照明复杂性（进而物理精度）更重要。

当时许多从业者还认为，基于物理的方法对生产来说是不可取的：计算机图形的一大事情是，一个人可以欺骗现实而不受惩罚，以达到理想的艺术效果。例如，常规电影中的照明设计师通常难以放置光源，以便摄像机看不到光源，或者花费大量精力放置灯光来照亮演员，而不会在背景上发光太多。例如，计算机图形提供了实现光源模型的机会，该模型以相当简单的方式将字符的光线照射到背景对象上两倍。多年来，这种能力似乎比物理精度更有用。

视觉效果从业者谁有特别需要匹配渲染的图像，以拍摄现实世界的环境，率先捕捉现实世界的照明和阴影效果，并在20世纪90年代末和210年代初是物理方法的早期采用者。（见 Snow（2010）例如，ILM在这一领域的早期工作的历史。

在此期间，Blue Sky工作室在历史早期采用了基于物理的管道（Ohmer 1997）。1992年他们为Braun剃须刀制作的广告的真人形象引起了许多人的注意，他们的短片《Bunny》于1998年上映，是蒙特卡洛全局光照在制作中的早期例子。它的视觉外观与Reyes渲染的电影和短片大相径庭，广为人知。蓝天的后续故事片也遵循了这种方法。不幸的是，蓝天公司从未公布过他们方法的重要技术细节，限制了他们更广泛的影响力。

在21世纪早期，一些工作室使用精神光线追踪系统，主要用于视觉效果。这是一个非常高效的光线跟踪器，具有复杂的全局照明算法实现。其开发人员的主要重点是计算机辅助设计和产品设计应用程序，因此它缺乏处理极其复杂的场景的能力以及电影制作所需的大量纹理地图等功能。

继《Bunny》之后，另一个分水岭的时刻出现在2001年，Marcos Fajardo带着他的Arnold渲染器的早期版本来到了SIGGRAPH。他在蒙特卡罗图像合成课程中展示了图像，这些图像不仅具有复杂的几何形状、纹理和全局照明，而且在数十分钟内呈现。虽然这些场景与当时电影制作中使用的场景并不复杂，但他的结果表明，在复杂场景中，全局光照提供了许多创作机会。

Fajardo将Arnold带到了Sony影业影像厂，在那里，工作开始将其转换为具有生产能力的基于物理的渲染系统。高效运动模糊、可编程着色、支持复杂场景和延迟加载场景几何体以及支持纹理缓存（场景中的纹理只有一小部分保留在内存中）的工作都是需要解决的重要领域。Arnold最初在电影《Monster House》中使用过，现在通常可以作为产品使用。

在 2000 年代中期，Pixar的 RenderMan渲染器开始支持混合光栅化和光线跟踪算法，并包括一些创新算法，用于计算复杂场景中的全局光照解决方案。RenderMan最近被重写为基于物理的光线跟踪器，遵循pbrt的一般系统体系结构（Christensen2015年 ）。

基于物理的蒙特卡罗渲染方法在制作中取得成功的主要原因之一是它们最终提高了艺术家的生产力。一些重要因素包括：
* 所涉及的算法基本上只有一个质量旋钮：每个像素要采集多少个样本;这对艺术家非常有帮助。光线跟踪算法也适合通过每像素只采集几个样本来逐步优化和快速计算粗略预览;基于光栅化的渲染器没有等效功能。
* 采用基于物理的反射模型使设计表面材料更加容易。早些时候，当使用不一定节省能源的反射模型时，对象可能会被放置在单个照明环境中，同时调整其表面反射参数。该对象在该环境中可能看起来很好，但当移动到另一个照明环境时，它通常看起来完全错误，因为表面实际上反射的能量太少或太多：表面属性已设置为不合理的值。
* 使用光线跟踪计算的阴影质量比栅格化好得多。消除调整阴影贴图分辨率、偏差和其他参数的需要，消除了照明艺术家的不愉快任务。此外，基于物理的方法从方法本身带来弹跳照明和其他软照明效果，而不是作为艺术调整的手动过程。

在撰写本文时，基于物理的渲染被广泛用于为电影生成计算机生成的图像;图1.22 和 1.23显示了最近两部使用基于物理的方法的电影的图像。

![gravity](../img/Introduction/A_Brief_History_of_Physically_Based_Rendering/gravity.png)
图1.22：Gravity（2013年）以计算机生成的壮观的图像为特色，以体积散射和大量各向异性金属表面为现实空间环境。图像是使用Arnold生成的，Arnold是一个基于物理的渲染系统，负责全局光照。图片由Warner兄弟和Framestore提供。

![hobbit](../img/Introduction/A_Brief_History_of_Physically_Based_Rendering/hobbit.png)
图1.23：这张来自《The Hobbit: The Battle of the Five Armies》（2014年）的图像也使用基于物理的渲染系统呈现;角色具有异构的次地表面散射和大量的几何细节。图片由Weta Digital，由Warner兄弟和Metro-Goldwyn-Mayer提供。